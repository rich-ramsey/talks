@article{gigerenzer2018,
  title = {Statistical {{Rituals}}: {{The Replication Delusion}} and {{How We Got There}}},
  shorttitle = {Statistical {{Rituals}}},
  author = {Gigerenzer, Gerd},
  date = {2018-06-01},
  journaltitle = {Advances in Methods and Practices in Psychological Science},
  volume = {1},
  number = {2},
  pages = {198--218},
  publisher = {SAGE Publications Inc},
  issn = {2515-2459},
  doi = {10.1177/2515245918771329},
  url = {https://doi.org/10.1177/2515245918771329},
  urldate = {2023-07-18},
  abstract = {The “replication crisis” has been attributed to misguided external incentives gamed by researchers (the strategic-game hypothesis). Here, I want to draw attention to a complementary internal factor, namely, researchers’ widespread faith in a statistical ritual and associated delusions (the statistical-ritual hypothesis). The “null ritual,” unknown in statistics proper, eliminates judgment precisely at points where statistical theories demand it. The crucial delusion is that the p value specifies the probability of a successful replication (i.e., 1 – p), which makes replication studies appear to be superfluous. A review of studies with 839 academic psychologists and 991 students shows that the replication delusion existed among 20\% of the faculty teaching statistics in psychology, 39\% of the professors and lecturers, and 66\% of the students. Two further beliefs, the illusion of certainty (e.g., that statistical significance proves that an effect exists) and Bayesian wishful thinking (e.g., that the probability of the alternative hypothesis being true is 1 – p), also make successful replication appear to be certain or almost certain, respectively. In every study reviewed, the majority of researchers (56\%–97\%) exhibited one or more of these delusions. Psychology departments need to begin teaching statistical thinking, not rituals, and journal editors should no longer accept manuscripts that report results as “significant” or “not significant.”},
  langid = {english},
  file = {/Users/rramsey/Dropbox/docs/journals/cog_neuro/Gigerenzer_2018_Statistical RitualsStatistical Rituals.pdf}
}

@book{kruschke2014,
  title = {Doing {{Bayesian Data Analysis}}: {{A Tutorial}} with {{R}}, {{JAGS}}, and {{Stan}}},
  shorttitle = {Doing {{Bayesian Data Analysis}}},
  author = {Kruschke, John},
  date = {2014-11-11},
  eprint = {FzvLAwAAQBAJ},
  eprinttype = {googlebooks},
  publisher = {Academic Press},
  abstract = {Doing Bayesian Data Analysis: A Tutorial with R, JAGS, and Stan, Second Edition provides an accessible approach for conducting Bayesian data analysis, as material is explained clearly with concrete examples. Included are step-by-step instructions on how to carry out Bayesian data analyses in the popular and free software R and WinBugs, as well as new programs in JAGS and Stan. The new programs are designed to be much easier to use than the scripts in the first edition. In particular, there are now compact high-level scripts that make it easy to run the programs on your own data sets. The book is divided into three parts and begins with the basics: models, probability, Bayes’ rule, and the R programming language. The discussion then moves to the fundamentals applied to inferring a binomial probability, before concluding with chapters on the generalized linear model. Topics include metric-predicted variable on one or two groups; metric-predicted variable with one metric predictor; metric-predicted variable with multiple metric predictors; metric-predicted variable with one nominal predictor; and metric-predicted variable with multiple nominal predictors. The exercises found in the text have explicit purposes and guidelines for accomplishment. This book is intended for first-year graduate students or advanced undergraduates in statistics, data analysis, psychology, cognitive science, social sciences, clinical sciences, and consumer sciences in business.  Accessible, including the basics of essential concepts of probability and random sampling Examples with R programming language and JAGS software Comprehensive coverage of all scenarios addressed by non-Bayesian textbooks: t-tests, analysis of variance (ANOVA) and comparisons in ANOVA, multiple regression, and chi-square (contingency table analysis) Coverage of experiment planning R and JAGS computer programming code on website Exercises have explicit purposes and guidelines for accomplishment Provides step-by-step instructions on how to conduct Bayesian data analyses in the popular and free software R and WinBugs},
  isbn = {978-0-12-405916-0},
  langid = {english},
  pagetotal = {772},
  keywords = {Mathematics / Applied,Mathematics / Mathematical Analysis,Mathematics / Probability & Statistics / General}
}

@article{kruschke2018,
  title = {The {{Bayesian New Statistics}}: {{Hypothesis}} Testing, Estimation, Meta-Analysis, and Power Analysis from a {{Bayesian}} Perspective},
  author = {Kruschke, J. K. and Liddell, T. M.},
  date = {2018-02},
  journaltitle = {Psychon Bull Rev},
  edition = {2017/02/09},
  volume = {25},
  number = {1},
  eprint = {28176294},
  eprinttype = {pubmed},
  pages = {178--206},
  issn = {1531-5320 (Electronic) 1069-9384 (Linking)},
  doi = {10.3758/s13423-016-1221-4},
  url = {https://www.ncbi.nlm.nih.gov/pubmed/28176294},
  abstract = {In the practice of data analysis, there is a conceptual distinction between hypothesis testing, on the one hand, and estimation with quantified uncertainty on the other. Among frequentists in psychology, a shift of emphasis from hypothesis testing to estimation has been dubbed "the New Statistics" (Cumming 2014). A second conceptual distinction is between frequentist methods and Bayesian methods. Our main goal in this article is to explain how Bayesian methods achieve the goals of the New Statistics better than frequentist methods. The article reviews frequentist and Bayesian approaches to hypothesis testing and to estimation with confidence or credible intervals. The article also describes Bayesian approaches to meta-analysis, randomized controlled trials, and power analysis.},
  keywords = {*Bayes factor,*Bayes Theorem,*Bayesian inference,*Confidence interval,*Credible interval,*Effect size,*Equivalence testing,*Highest density interval,*Meta-analysis,*Null hypothesis significance testing,*Power analysis,*Randomized controlled trial,*Region of practical equivalence,*Statistics as Topic,Humans,Meta-Analysis as Topic,Research Design,Uncertainty}
}

@book{kurzStatisticalRethinkingSecondEd2023,
  title = {Statistical rethinking with brms, ggplot2, and the tidyverse: {{Second}} edition},
  author = {Kurz, A. Solomon},
  year = {2023},
  month = {jan},
  edition = {version 0.4.0},
  url = {https://bookdown.org/content/4857/}
}

@book{mcelreath2020,
  title = {Statistical Rethinking: {{A Bayesian}} Course with Examples in {{R}} and {{Stan}}},
  author = {McElreath, Richard},
  date = {2020},
  publisher = {CRC press},
  isbn = {0-429-63914-7}
}

@article{scheel2021,
  title = {Why Hypothesis Testers Should Spend Less Time Testing Hypotheses},
  author = {Scheel, Anne M. and Tiokhin, Leonid and Isager, Peder M. and Lakens, Daniël},
  date = {2021},
  journaltitle = {Perspectives on Psychological Science},
  volume = {16},
  pages = {744--755},
  publisher = {Sage Publications},
  location = {US},
  issn = {1745-6924},
  doi = {10.1177/1745691620966795},
  abstract = {For almost half a century, Paul Meehl educated psychologists about how the mindless use of null-hypothesis significance tests made research on theories in the social sciences basically uninterpretable. In response to the replication crisis, reforms in psychology have focused on formalizing procedures for testing hypotheses. These reforms were necessary and influential. However, as an unexpected consequence, psychological scientists have begun to realize that they may not be ready to test hypotheses. Forcing researchers to prematurely test hypotheses before they have established a sound “derivation chain” between test and theory is counterproductive. Instead, various nonconfirmatory research activities should be used to obtain the inputs necessary to make hypothesis tests informative. Before testing hypotheses, researchers should spend more time forming concepts, developing valid measures, establishing the causal relationships between concepts and the functional form of those relationships, and identifying boundary conditions and auxiliary assumptions. Providing these inputs should be recognized and incentivized as a crucial goal in itself. In this article, we discuss how shifting the focus to nonconfirmatory research can tie together many loose ends of psychology’s reform movement and help us to develop strong, testable theories, as Paul Meehl urged. (PsycInfo Database Record (c) 2021 APA, all rights reserved)},
  keywords = {Auditory Stimulation,Concepts,Experimental Replication,Hypothesis Testing,Measurement,Social Sciences,Test Validity,Theories},
  file = {/Users/rramsey/Dropbox/docs/journals/cog_neuro/Scheel_2021_Why hypothesis testers should spend less time testing hypothesesWhy hypothesis testers should spend less time testing hypotheses.pdf;/Users/rramsey/Zotero/storage/SQRRKF38/2021-66119-007.html}
}

@book{winter2019,
  title = {Statistics for {{Linguists}}: {{An Introduction Using R}}},
  shorttitle = {Statistics for {{Linguists}}},
  author = {Winter, Bodo},
  date = {2019-10-30},
  eprint = {8cbADwAAQBAJ},
  eprinttype = {googlebooks},
  publisher = {Routledge},
  abstract = {Statistics for Linguists: An Introduction Using R is the first statistics textbook on linear models for linguistics. The book covers simple uses of linear models through generalized models to more advanced approaches, maintaining its focus on conceptual issues and avoiding excessive mathematical details. It contains many applied examples using the R statistical programming environment. Written in an accessible tone and style, this text is the ideal main resource for graduate and advanced undergraduate students of Linguistics statistics courses as well as those in other fields, including Psychology, Cognitive Science, and Data Science.},
  isbn = {978-1-351-67743-1},
  langid = {english},
  pagetotal = {327},
  keywords = {Education / Teaching / Subjects / Arts & Humanities,Education / Teaching / Subjects / Social Science,Language Arts & Disciplines / Linguistics / General,Mathematics / Probability & Statistics / General}
}

@article{flake2020,
  title = {Measurement Schmeasurement: {{Questionable}} Measurement Practices and How to Avoid Them},
  shorttitle = {Measurement Schmeasurement},
  author = {Flake, Jessica Kay and Fried, Eiko I.},
  date = {2020},
  journaltitle = {Advances in Methods and Practices in Psychological Science},
  volume = {3},
  pages = {456--465},
  publisher = {Sage Publications},
  location = {US},
  issn = {2515-2467},
  doi = {10.1177/2515245920952393},
  abstract = {In this article, we define questionable measurement practices (QMPs) as decisions researchers make that raise doubts about the validity of the measures, and ultimately the validity of study conclusions. Doubts arise for a host of reasons, including a lack of transparency, ignorance, negligence, or misrepresentation of the evidence. We describe the scope of the problem and focus on how transparency is a part of the solution. A lack of measurement transparency makes it impossible to evaluate potential threats to internal, external, statistical-conclusion, and construct validity. We demonstrate that psychology is plagued by a measurement schmeasurement attitude: QMPs are common, hide a stunning source of researcher degrees of freedom, and pose a serious threat to cumulative psychological science, but are largely ignored. We address these challenges by providing a set of questions that researchers and consumers of scientific research can consider to identify and avoid QMPs. Transparent answers to these measurement questions promote rigorous research, allow for thorough evaluations of a study’s inferences, and are necessary for meaningful replication studies. (PsycInfo Database Record (c) 2021 APA, all rights reserved)},
  keywords = {Behavioral Sciences,Construct Validity,Experimental Replication,Measurement,Psychometrics,Test Validity},
  file = {/Users/rramsey/Dropbox/docs/journals/cog_neuro/Flake_Fried_2020_Measurement schmeasurementMeasurement schmeasurement.pdf;/Users/rramsey/Zotero/storage/MCGBCTF5/2020-98063-002.html}
}

